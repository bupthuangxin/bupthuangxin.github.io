<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[【置顶】机器学习学习总结]]></title>
      <url>%2F2048%2F10%2F24%2F%E3%80%90%E7%BD%AE%E9%A1%B6%E3%80%91%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%20%2F</url>
      <content type="text"><![CDATA[从关注机器学习到现在也很久的时间，一直在自我摸索中前进，本篇就推荐下看过的好书及一些经典的技术博客，让想接触机器学习的同学少走弯路。本人渣渣一枚，如有误导劳烦指出。 《斯坦福机器学习课程》Andrew Ng（五星） 吴恩达大神的机器学习课程应该是很多学生的启蒙课程。推荐将英文原版的讲义打印出来，边听课边学习，前面的课程比较重要，强化学习等课程不适合初学者。博主第一遍看的时候很多东西都没听懂，囫囵吞枣，最近看了第二遍，收获满满。 《机器学习实战》（两星） 这本书主要是用python实现了一些算法，没有很晦涩的数学推导。算法的实现也比较简单，不太推荐读这本书，如果为了巩固一下python语言的基本使用，可以读一下。 《统计学习方法》李航（五星） 李航博士的书，里面有很多数学推导，只要明白基础的微积分，概率论以及线性代数知识，看不明白的数学知识遇见现查找就可以。博主看了几遍，很多知识都是反复看才能烂熟于心。本书主要介绍了是监督学习的分类算法，如果需要全面学习其他知识，需要配合别的书籍。强烈推荐。 《机器学习》周志华（四星） 《统计学习方法》主要介绍监督学习，这本书介绍了非监督学习，聚类算法，PCA及一些基础知识比如交叉验证，数据预处理，已经模型评估等，还有一些学习理论，VC维等进阶知识。 廖雪峰的python教程（五星） 这个python教程，非常容易理解，强烈推荐。传送门 《利用python进行数据分析》(五星) 这本书主要讲解了numpy，pandas，matplotlib等数据处理的库。当一本小型工具书使用，配合Sklearn机器学习算法包使用，上手效率很高。 《UFLDL Tutorial》Andrew Ng（四星） 了解深度学习就是从斯坦福的网站开始的，文章如果不能理解，多google相关博客。传送门 《Neural Networks and Deep Learning》Michael Nielsen（三星） 这本书网上有中文版，可是读一读，内容比较浅显易懂，适合深度学习入门。 《Spark快速大数据分析》（三星） 这本书简要介绍了spark的机制，本书用三种语言示例，如果对大数据分析有兴趣的话，这本书可以算是一个入门的书籍，读起来比较轻松。 《大话数据结构》（五星） 非常值得数据结构入门，书中画了很多图，看书的时候很容易理解，且不容易忘记。 《数据结构与算法分析》（四星） 值得看的一本书，如果对算法导论充满抵触的话，这本书可以满足对数据结构和基础算法的理解。 《java编程思想》 java最经典的书籍。博主准备在最近一个月把它读完。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[生成学习与判别学习]]></title>
      <url>%2F2017%2F04%2F11%2F%E7%94%9F%E6%88%90%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%88%A4%E5%88%AB%E5%AD%A6%E4%B9%A0%2F</url>
      <content type="text"><![CDATA[判别学习与生成学习 第二遍看吴恩达的视频，总结一下关于生成模型和判别模型。以下是几点它们之间的对比。 生成模型（Generaive Model）一般以概率的方式描述了数据的产生方式，通过对模型采样就可以产生数据。 判别模型（Discriminative Model）对数据之间的映射关系建模，而不考虑数据本身是如何生成的。判别模型可以根据给定的数据x预测对应的y（回归），或根据不同的映射结果y来区分给定的数据x（分类）。但模型自身并不能产生数据。生成模型是对条件概率p(x|y)和先验概率p(y)建模，通过贝叶斯公式 间接求目标变量的概率。 判别模型是对p(y|x)建模，直接求出目标变量的概率。生成模型是对两个类别分别进行建模，用新的样例去匹配两个模型，匹配度较 高的作为新样例的类别，比如良性肿瘤与恶性肿瘤的分类，首先对两个类别分别 建模，比如分别计算两类肿瘤是否扩散的概率，计算肿瘤大小大于某个值的概率 等等；再比如狗与大象的分类，分别对狗与大象建模，比如计算体重大于某个值 的概率，鼻子长度大于某个值的概率等等。判别学习直接对问题进行求解，比如二类分类问题，不管是感知器算法还是LR算法，都是在空间中寻找一条直线从而把两种类别的样例分开，对于新的样例只要判断在直线的哪一侧即可；这种直接对问题求解的方法。 生成模型对数据分布做出的假设要求更强。 优点:在数据分布符合做出的假设情况下，生成模型效果更好且对样本的数量需求较小缺点:如果数据分布不符合假设，则效果较差，即鲁棒性较差。 判别模型对数据分布的假设要求不强。 优点:鲁棒性较好，即使在模型不符合数据假设的情况下，效果通常也会比较好，这也导致了在实际中判别模型使用的更广泛。 缺点:在数据分布符合生成模型假设的情况下，效果没有生成模型好。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[PCA主成分分析]]></title>
      <url>%2F2017%2F04%2F04%2FPCA%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[&emsp;&emsp;降维的概念，有一个很好的例子可以参考。看电视的时候屏幕上有成百上千万的像素点，那么其实每个画面都是一个上千万维度的数据；但是我们在观看的时候大脑自动把电视里面的场景放在我们所能理解的三维空间来理解，这个很自然的过程其实就是一个降维（dimensionallity reduction）的过程。 （一）为什么要降维？ 数据&emsp;&emsp;当我们获取到数据之后，可以拿到数以万计的特征，那这些大量特征要全部带入模型中进行训练么？显然不是，当特征越多，训练出来的模型越复杂，训练速度也一定很慢，最终还会引起过拟合的危险，所以降维是一种解决方法。 可视化&emsp;&emsp;大量的特征在空间中我们可能无法显性的理解，降维之后对数据的可视化提供了帮助。 （二）主成分分析&emsp;&emsp;PCA通过线性变换将原始数据变换为一组各维度线性无关的表示，可用于提取数据的主要特征分量，常用于高维数据的降维。 PCA和LR的区别：1.PCA的衡量标准是正交距离，LR的衡量标准是真实值和预测值的垂直距离。2.PCA跟y值无关，只想找一个平面，使各个特征投影到这个平面后使各个点方差最大；LR是通过X去预测y。 （三）PCA简易数学推导数学知识回忆&emsp;&emsp;内积的定义：$$(a_1,a_2,\cdots,a_n)^\mathsf{T}\cdot (b_1,b_2,\cdots,b_n)^\mathsf{T}=a_1b_1+a_2b_2+\cdots+a_nb_n$$内积可以将两个向量计算成一个实数。假设向量A和B都是二维向量，\(A=(x_1,y_1)\)，\(B=(x_2,y_2)\)，其在二维坐标系中是两条有向线段。当A和B的夹角是a，则A到B的投影矢量长度为\(|A|cos(a)\)，其中\(|A|=\sqrt{x_1^2+y_1^2}\)是A的标量长度。这样我们就可以看出投影和内积的关系了。\(A\cdot B=|A||B|cos(a)\)即A和B的内积就是A投影到B的长度乘以B的模，若假设B的模为1，那么\(A\cdot B=|A|cos(a)\)即设向量B的模为1，则A与B的内积值等于A向B所在直线投影的矢量长度比如向量(5，6)其实就是此向量向x轴和y轴的单位向量做的投影，其长度分别为5和6为，即(x,y)可以表示为\(x(1,0)^\mathsf{T}+y(0,1)^\mathsf{T}\)，这里的(1,0)和(0,1)就是坐标系中的一组基。所以描述向量就是先确定一组基，给出在基所在的各个直线的投影长度。&emsp;&emsp;当然我们可以在坐标系中选择另外一组正交基（可以选择非正交基，但是正交基理解直观且性质好），那么向量(5,6)在新的一组基中的表示就会发生变化。得到新的坐标很容易，先构造一个矩阵，两行为两个基，乘以原向量，其结果就是新基的坐标。一般的，如果我们有M个N维向量，想将其变换为由R个N维向量表示的新空间中，那么首先将R个基按行组成矩阵A，然后将向量按列组成矩阵B，那么两矩阵的乘积AB就是变换结果，其中AB的第m列为A中第m列变换后的结果。这里的R可以小于N，R就是决定了变换后数据的维度。即R×N的矩阵乘以N×M的矩阵得到R×M的矩阵，意味着M个R维向量。 优化目标&emsp;&emsp;选择不同的基可以对同样一组数据给出不同的表示，而且如果基的数量少于向量本身的维数，则可以达到降维的效果。但是还有一个最关键的问题：如何选择基才是最优的。或者说，如果我们有一组N维向量，现在要将其降到K维（K小于N），那么我们应该如何选择K个基才能最大程度保留原有的信息？&emsp;&emsp;直观的想法是投影到此基的新值尽可能的分散。分散程度可以用方差表示，假设均值为0。这是二维变换成一维，如果更高维的，找到第一个基之后，如何选择第二个基呢，直观的想法是让两个字段尽可能多的表示原始信息，不希望它们存在相关性，协方差可以表示相关性。所以至此优化的目标变成将一组N维向量降为K维，其目标是选择K个单位正交基，使得原始数据变换到这组基上后，各字段两两间协方差为0，而字段的方差则尽可能大。 优化过程&emsp;&emsp;数学很神奇，设我们有m个n维数据记录，将其按列排成n乘m的矩阵X，设\(C=\frac{1}{m}XX^\mathsf{T}\)，则C是一个对称矩阵，其对角线分别个各个字段的方差，而第i行j列和j行i列元素相同，表示i和j两个字段的协方差。根据优化目标，只需将协方差矩阵除对角元素外其他元素都为0，且对角元素按从大到小排列。设原始数据矩阵X对应的协方差矩阵为C，而P是一组基按行组成的矩阵，设Y=PX，则Y为X对P做基变换后的数据。设Y的协方差矩阵为D，\(D=PCP^\mathsf{T}\)，优化目标变成了寻找一个矩阵P，满足\(PCP^\mathsf{T}\)是一个对角矩阵，并且对角元素按从大到小依次排列，那么P的前K行就是要寻找的基，用P的前K行组成的矩阵乘以X就使得X从N维降到了K维并满足上述优化条件。根据线性代数知识可知，P是协方差矩阵的特征向量单位化后按行排列出的矩阵，其中每一行都是C的一个特征向量。如果设P按照特征值从大到小，将特征向量从上到下排列，则用P的前K行组成的矩阵乘以原始数据矩阵X，就得到了我们需要的降维后的数据矩阵Y。 算法步骤总结&emsp;&emsp;设有m条n维数据。 将原始数据按列组成n行m列矩阵X 将X的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值 求出协方差矩阵\(C=\frac{1}{m}XX^\mathsf{T}\) 求出协方差矩阵的特征值及对应的特征向量 将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P Y=PX即为降维到k维后的数据 （四）主成分的个数选择&emsp;&emsp;可以从错误率来考虑主成分的个数，可以设置一个阈值，当错误率小于阈值时，说明这样选取主成分是可行的。 （五）建议&emsp;&emsp; PCA可以提出主成分解决过拟合问题，但不要用PCA解决overfitting，还是用其他的方法比如正则化去减小过拟合。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Mac OS X安装Hadoop2.7和Hbase1.1]]></title>
      <url>%2F2016%2F04%2F24%2FMac%20OS%20X%E5%AE%89%E8%A3%85Hadoop2.7%E5%92%8CHbase1.1%2F</url>
      <content type="text"><![CDATA[&emsp;&emsp;由于网上安装这些大数据工具都是基于Linux的，关于Mac的文章鱼龙混杂，正好这两天成功在自己机器上安装成功伪分布式的Hadoop和Hbase，记录一下也与网友分享。 安装Hadoop1.安装Homebrew&emsp;&emsp;关于Homebrew可以查看其官网 传送门。&emsp;&emsp;安装Homebrew非常简单，只需下面这样的命令行:1$ ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 2.ssh localhost&emsp;&emsp;因为安装hadoop需要远程登入的功能,所以需要安装ssh工具。 Mac OS X只需在“系统偏好设置”的“共享”的“远程登录”勾选就可以使用ssh了。关于ssh的原理可以查看相关博客 传送门。如果没有生成过ssh公钥，就使用命令：(查看~/.ssh/id_dsa和~/.ssh/id_dsa.pub存不存在就知道之前有没有生成过公钥，或者直接执行ssh localhost看能否成功) &emsp;&emsp;由于每次远程登陆ssh localhost会输入密码，所以以下命令是为了将自己的公钥存到对方的公钥保存文件夹中，避免每次输密码的麻烦:12$ ssh-keygen -t rsa -P "" $ cat $HOME/.ssh/id_rsa.pub &gt;&gt; $HOME/.ssh/authorized_keys 3.安装Hadoop1$ brew install hadoop &emsp;&emsp;这样Hadoop就安装成功了，我安装的是Hadoop2.7.1。默认下载路径是/usr/local/Cellar/hadoop下面。&emsp;&emsp;接下来就是配置文件的修改：hadoop-env.sh文件在/usr/local/Cellar/hadoop/2.7.1/libexec/etc/hadoop/hadoop-env.sh。将1export HADOOP_OPTS="$HADOOP_OPTS -Djava.net.preferIPv4Stack=true" 改为1export HADOOP_OPTS="$HADOOP_OPTS -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc=" Core-site.xml文件在/usr/local/Cellar/hadoop/2.7.1/libexec/etc/hadoop/core-site.xml。编辑此文件:1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/Cellar/hadoop/hdfs/tmp&lt;/value&gt; &lt;description&gt;A base for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 注： fs.default.name保存了NameNode的位置，HDFS和MapReduce组件都需要用到它，这就是它出现在core-site.xml 文件中而不是 hdfs-site.xml文件中的原因。 &emsp;&emsp;mapred-site.xml可能文件名为 mapred-site.xml.templete，文件在/usr/local/Cellar/hadoop/2.7.1/libexec/etc/hadoop/mapred-site.xml编辑此文件:123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;localhost:9010&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 注：变量mapred.job.tracker 保存了JobTracker的位置，因为只有MapReduce组件需要知道这个位置，所以它出现在mapred-site.xml文件中。 &emsp;&emsp;hdfs-site.xml文件在/usr/local/Cellar/hadoop/2.7.1/libexec/etc/hadoop/hdfs-site.xml。编辑此文件:123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 注：变量dfs.replication指定了每个HDFS数据库的复制次数。 通常为3, 由于我们只有一台主机和一个伪分布式模式的DataNode，将此值修改为1。 &emsp;&emsp;到此为止，配置文件编辑完毕。&emsp;&emsp;接下来是进到 hadoop 的安装目录 /usr/local/Cellar/hadoop/2.7.1/sbin,然后执行 ./start-dfs.sh 和 ./start-yarn.sh 就可以启动 Hadoop了。&emsp;&emsp;在启动Hadoop之前要先格式化hdfs:1$ hadoop namenode -format &emsp;&emsp;这时用./start-dfs.sh和 ./start-yarn.sh启动Hadoop。可以输入jps命令查看Hadoop是否正常运行。 4.运行例子&emsp;&emsp;安装完之后，需要运行一个例子，看看Hadoop是否正常工作。12$ hadoop jar &lt;path to the hadoop-examples file&gt; pi 10 100$ hadoop jar /usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar pi 2 5 &emsp;&emsp;得到的结果是:123456Wrote input for Map #0Wrote input for Map #1Starting Job...Job Finished in 1.685 secondsEstimated value of Pi is 3.60000000000000000000 &emsp;&emsp;然后可以通过Web端进行监控。&emsp;&emsp;Resource Manager: http://localhost:50070&emsp;&emsp;JobTracker: http://localhost:8088&emsp;&emsp;Specific Node Information: http://localhost:8042&emsp;&emsp;通过他们可以访问 HDFS filesystem, 也可以取得结果输出文件。 安装Hbase1.安装1$ brew install hbase 默认安装路径是/usr/local/Cellar/hbase/1.1.2，笔者安装的版本为1.1.2。 2.配置HBase&emsp;&emsp;在conf/hbase-env.sh文件中设置JAVA_HOME12345$ cd /usr/local/Cellar/hbase/1.0.0/libexec/conf$ vim hbase-env.sh配置你的java环境（笔者的jdk为1.8版本）export JAVA_HOME="JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_40.jdk/Contents/Home"export HBASE_MANAGE_XK=true &emsp;&emsp;在conf/hbase-site.xml设置HBase的分布式模式1$ vim hbase-site.xml 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; //Here you have to set the path where you want HBase to store its files. &lt;value&gt;hdfs://localhost:8020/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hbase.rootdir路径一定要跟hadoop中core-site.xml中fs.default.name相同在启动HBase之前, 请先启动Hadoop, 使之运行 &emsp;&emsp;前面已经介绍了Hadoop的启动方法，接下来介绍HBase的方法。&emsp;&emsp;/usr/local/Cellar/hbase/1.1.2/bin/start-hbase.sh 提供HBase的启动:1234567891011121314$ ./start-hbase.sh starting master, logging to /usr/local/Cellar/hbase/1.1.2/libexec/bin/../logs/hbase-huangxin-master-huangxinMacBook-Pro.local.out$ jps #验证是否启动成功, 包含HMaster和HRegionServer说明启动成功2176 16850 HRegionServer12500 SecondaryNameNode12708 NodeManager12616 ResourceManager16696 HQuorumPeer16920 Jps12394 DataNode16746 HMaster12893 NameNode &emsp;&emsp;然后进行操作HBase1234567891011$ hbase shell #启动HBase ShellSLF4J: Class path contains multiple SLF4J bindings.SLF4J: Found binding in [jar:file:/usr/local/Cellar/hbase/1.1.2/libexec/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: Found binding in [jar:file:/usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]2016-04-24 14:13:10,472 WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableHBase Shell; enter 'help&lt;RETURN&gt;' for list of supported commands.Type "exit&lt;RETURN&gt;" to leave the HBase ShellVersion 1.1.2, rcc2b70cf03e3378800661ec5cab11eb43fafe0fc, Wed Aug 26 20:11:27 PDT 2015 &emsp;&emsp;这种情况是Hadoop文件中slf4j-log4j12-1.7.10.jar与Hbase文件额slf4j-log4j12-1.7.5.jar冲突，删除其中一个就好。123456$ hbase shell #启动HBase Shell2016-04-24 14:29:16,929 WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableHBase Shell; enter 'help&lt;RETURN&gt;' for list of supported commands.Type "exit&lt;RETURN&gt;" to leave the HBase ShellVersion 1.1.2, rcc2b70cf03e3378800661ec5cab11eb43fafe0fc, Wed Aug 26 20:11:27 PDT 2015 &emsp;&emsp;说明成功。接下来试着编辑HBase12345678910111213hbase(main):001:0&gt; create 'student', 'description', 'course'#创建表名为student的表, 指明两个列名, 分别为description和course0 row(s) in 1.6060 seconds=&gt; Hbase::Table - studenthbase(main):002:0&gt; list 'student' #列出list表信息TABLE student 1 row(s) in 0.0280 secondshbase(main):003:0&gt; exit #退出shell$ ./bin/stop-hbase.sh #停止运行HBasestopping hbase.......................localhost: stopping zookeeper.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式大杂烩]]></title>
      <url>%2F2016%2F04%2F02%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%A4%A7%E6%9D%82%E7%83%A9%20%2F</url>
      <content type="text"><![CDATA[&emsp;&emsp;设计模式（Design pattern）是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了可重用代码、让代码更容易被他人理解、保证代码可靠性。 毫无疑问，设计模式于己于他人于系统都是多赢的；设计模式使代码编制真正工程化；设计模式是软件工程的基石脉络，如同大厦的结构一样。&emsp;&emsp;LZ今天推荐一位牛人的博客，里面一共27篇关于设计模式的文章，每一个设计模式都讲解的非常清楚，且简单易懂。&emsp;&emsp;设计模式学习传送门]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ServletConfig和ServletContext以及读取资源的方法]]></title>
      <url>%2F2016%2F03%2F16%2FServletConfig%E5%92%8CServletContext%E5%AF%B9%E8%B1%A1%E4%BB%A5%E5%8F%8A%E8%AF%BB%E5%8F%96%E8%B5%84%E6%BA%90%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
      <content type="text"><![CDATA[ServletConfig对象当servlet配置了初始化参数后，web容器在创建servlet实例对象时，会自动将这些初始化参数封装到ServletConfig对象中，并在调用servlet的init方法时，将ServletConfig对象传递给servlet。进而，程序员通过ServletConfig对象就可以得到当前servlet的初始化参数信息。 //获得配置文档中&lt;init-param&gt;标签下name对应的value this.getServletConfig().getInitParameter("name"); //获取所有初始化参数 Enumeration e = this.getServletConfig().getInitParameterNames(); while(e.hasMoreElements()){ String name = (String) e.nextElement(); String value = this.getServletConfig().getInitParameter(name); System.out.println(name + "=" + value); } 一般应用于1.获取字符集编码String charset = this.getServletConfig().getInitParameter(&quot;charset&quot;);2.获得数据库连接信息String url = this.getServletConfig().getInitParameter(&quot;url&quot;);String username = this.getServletConfig().getInitParameter(&quot;username&quot;);String password = this.getServletConfig().getInitParameter(&quot;password&quot;);3.获得配置文件String configFile = this.getServletConfig().getInitParameter(&quot;config&quot;); ServletContext对象web容器在启动时，它会为每个WEB应用程序都创建一个对应的ServletContext对象，它代表当前web应用。当应用关闭(或reload tomcat)时，自动销毁。1.多个servlet通过ServletConfig()实现数据共享由于一个web应用中的所有Servlet共享同一个ServletContext对象，因此Servlet对象之间可以通过ServletContext对象来实现通讯。ServletContext对象通常也被称之为context域对象。 //servletContext域对象 ServletContext servletcontext = this.getServletContext(); //向域中存了一个属性 servletcontext.setAttribute("String",object); //另一个servlet ServletContext servletcontext = this.getServletContext(); //获取域中的属性 String value = (String) context.getAttribute("String"); 2.通过servletContext对象获取到整个web应用的配置信息获取单个servlet配置信息用servletConfig，当配置信息是全体时： &lt;context-param&gt; &lt;param-name&gt;name&lt;/param-name&gt; &lt;param-value&gt;huangxin&lt;/param-value&gt; &lt;/context-param&gt; 那么用 this.getServletContext().getInitParameter(&quot;name&quot;),可以取出配置信息。3.通过servletContext对象实现转发this.getServletContext().getRequestDispatcher(&quot;/...&quot;).forward(request, response);4.通过servletContext对象读取资源文件在web工程中，我们一般来说，是不能采用传统方式读取配置文件的，因为相对的是jvm的启动目录(tomcat的bin目录)，所以我们要使用web绝对目录来获取配置文件的地址。1）使用ServletContext的getResourceAsStream方法：返回资源文件的读取字节流 //db.properties在webRoot目录下 InputStream in = this.getServletContext().getResourceAsStream("/db.properties"); Properties prop = new Properties(); prop.load(in); String url = prop.getProperty("url"); 2）使用ServletContext的getRealPath方法，获得文件的完整绝对路径path，再使用字节流读取path下的文件（除了可以获取数据，还可以获取资源文件的名称） //文件imgs在webRoot目录下 String path = this.getServletContext().getRealPath("/imgs/Sunset.jpg"); FileInputStream in = new FileInputStream(path); Properties prop = new Properties(); prop.load(in); String url = prop.getProperty("url"); 3）当资源文件放在src路径下，上述方法不可行，应该用类加载器读取 类名.class.getClassLoader().getResource("db.properties");]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[会话技术session]]></title>
      <url>%2F2016%2F03%2F16%2F%E4%BC%9A%E8%AF%9D%E6%8A%80%E6%9C%AFsession%2F</url>
      <content type="text"><![CDATA[会话概念会话可简单理解为：用户开一个浏览器，点击多个超链接，访问服务器多个web资源，然后关闭浏览器，整个过程称之为一个会话。每个用户在使用浏览器与服务器进行会话的过程中，不可避免各自会产生一些数据，程序要想办法为每个用户保存这些数据。 保存会话数据的两种技术cookie机制 1.Cookie是客户端技术。理论上，一个用户的所有请求操作都应该属于同一个会话，而另一个用户的所有请求操作则应该属于另一个会话，二者不能混淆。例如，用户A在超市购买的任何商品都应该放在A的购物车内，不论是用户A什么时间购买的，这都是属于同一个会话的，不能放入用户B或用户C的购物车内，这不属于同一个会话。2.而Web应用程序是使用HTTP协议传输数据的。HTTP协议是无状态的协议。一旦数据交换完毕，客户端与服务器端的连接就会关闭，再次交换数据需要建立新的连接。这就意味着服务器无法从连接上跟踪会话。即用户A购买了一件商品放入购物车内，当再次购买商品时服务器已经无法判断该购买行为是属于用户A的会话还是用户B的会话了。要跟踪该会话，必须引入一种机制。3.Cookie实际上是一小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie。客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查该Cookie，以此来辨认用户状态。 session机制 Session是服务器端技术。服务器在运行时可以为每一个用户的浏览器创建一个其独享的session对象，由于session为用户浏览器独享，所以用户在访问服务器的web资源时，可以把各自的数据放在各自的session中，当用户再去访问服务器中的其它web资源时，其它web资源再从用户各自的session中取出数据为用户服务。 session工作原理浏览器访问web服务器，web服务器访问servlet后，当第一次访问session时，就自动创建此浏览器独享的session，此session是由key-value组成，key是String，value是object。当request访问servlet1时，建立此浏览器对应的session，并为此session分配session id，response时在cookie中回一个JSESSIONID(set-cookie中)，当此浏览器再次发送http请求时，会在cookie中顺带session id，服务器根据id号寻找与之匹配的session。 创建session//获取session 当没有就自动创建 HttpSession session=request.getSession(); //给该session放入属性 session.setAttribute("uname", object); //取出属性 String uname=(object) session.getAttribute("uname"); 具体代码请参考：Github地址：创建sessionGithub地址：取出session 生命周期1.cookie的生命周期是单个设置的，为累计时间，而session得生命周期为整体设置，为发呆时间(只要访问一次就重新计时)。 HttpSession session=request.getSession(); session.setMaxInactiveInterval(30)//30s 如果想要配置单个项目的发呆时间，配置如下： &lt;session-config&gt; &lt;session-timeout&gt;30&lt;/session-timeout&gt; &lt;/session-config&gt; 2.当重启tomcat，reload或者关机时，session失效。可以强制让其失效，session.invalidate()一般用于安全退出，希望某个属性失效用session.removeAttribute()。 案例：利用session实现验证码功能Github地址：登陆页面Github地址：处理页面Github地址：创建验证码思路：创建验证码图片，并把验证码内容存入session中，再获取用户输入的验证码，将两者进行比较，若相同验证成功，进一步去数据库验证用户名和密码等信息。 案例：session+cookie关闭浏览器，session是不会消失的，它一直存在于服务器的内存中，只有到销毁时间过后，session才会在服务器端消失。一般情况下cookie不会保存session id的，只有我们强行把session id写在cookie中浏览器端才会保存，这样当我们利用cookie携带session id就可以访问原来已经创建好的session了。 HttpSession session=request.getSession(); session.setAttribute("username", "BUPT"); //把session id保存在cookie中 Cookie cookie=new Cookie("JSESSIONID",session.getId()); cookie.setMaxAge(3600); response.addCookie(cookie); //访问 在此访问此项目其他的servlet时，浏览器http请求中包括了cookie信息 //所以自动匹配了session，直接读取session属性即可 String name=(String) request.getSession().getAttribute("username"); 具体代码请参考：Github地址：cookie+sessionGithub地址：关浏览器再获取session 案例：当禁用cookie后，怎样使用session由于cookie中包含session id信息，如果cookie遭到禁用的话，session也会随之无法使用，那么在用户禁用cookie后，怎么才能继续使用session呢。 利用URL重写，URL地址重写是对客户端不支持Cookie的解决方案。URL地址重写的原理是将该用户Session的id信息重写到URL地址中。服务器能够解析重写后的URL获取Session的id。这样即使客户端不支持Cookie，也可以使用Session来记录用户状态。HttpServletResponse类提供了encodeURL(Stringurl)实现URL地址重写。 String url=response.encodeURL(&quot;/myCart/BuyBookCl?id=1&amp;name=java&quot;);该方法会自动判断客户端是否支持Cookie。如果客户端支持Cookie，会将URL原封不动地输出来。如果客户端不支持Cookie，则会将用户Session的id重写到URL中。/myCart/BuyBookCl;jsessionid=0CCD096E7F8D97B0BE608AFDC3E1931E?id=1&amp;name=java具体代码请参考：Github地址：购物车项目]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[会话技术cookie]]></title>
      <url>%2F2016%2F03%2F14%2F%E4%BC%9A%E8%AF%9D%E6%8A%80%E6%9C%AFcookie%2F</url>
      <content type="text"><![CDATA[会话概念会话可简单理解为：用户开一个浏览器，点击多个超链接，访问服务器多个web资源，然后关闭浏览器，整个过程称之为一个会话。每个用户在使用浏览器与服务器进行会话的过程中，不可避免各自会产生一些数据，程序要想办法为每个用户保存这些数据。 保存会话数据的两种技术cookie机制 1.Cookie是客户端技术。理论上，一个用户的所有请求操作都应该属于同一个会话，而另一个用户的所有请求操作则应该属于另一个会话，二者不能混淆。例如，用户A在超市购买的任何商品都应该放在A的购物车内，不论是用户A什么时间购买的，这都是属于同一个会话的，不能放入用户B或用户C的购物车内，这不属于同一个会话。2.而Web应用程序是使用HTTP协议传输数据的。HTTP协议是无状态的协议。一旦数据交换完毕，客户端与服务器端的连接就会关闭，再次交换数据需要建立新的连接。这就意味着服务器无法从连接上跟踪会话。即用户A购买了一件商品放入购物车内，当再次购买商品时服务器已经无法判断该购买行为是属于用户A的会话还是用户B的会话了。要跟踪该会话，必须引入一种机制。3.Cookie实际上是一小段的文本信息。客户端请求服务器，如果服务器需要记录该用户状态，就使用response向客户端浏览器颁发一个Cookie。客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查该Cookie，以此来辨认用户状态。 session机制 Session是服务器端技术。服务器在运行时可以为每一个用户的浏览器创建一个其独享的session对象，由于session为用户浏览器独享，所以用户在访问服务器的web资源时，可以把各自的数据放在各自的session中，当用户再去访问服务器中的其它web资源时，其它web资源再从用户各自的session中取出数据为用户服务。 cookie应用//cookie中文处理 String name=java.net.URLEncoder.encode("黄鑫","utf-8"); //创建cookie Cookie cookie=new Cookie("name",name); //设置cookie的生命周期 cookie.setMaxAge(3600); //把cookie信息回写给浏览器，响应头Set-Cookie中内容 response.addCookie(cookie); //读取所有cookie信息再筛选 Cookie cookies[]=request.getCookies(); for(int i=0;i&lt;cookies.length;i++){ Cookie cookie=cookies[i]; if(cookie.getName().equals("name")){ //对中文进行解码 String val=java.net.URLDecoder.decode(cookie.getValue(),"utf-8"); out.println(cookie.getName()+" "+val); } } 具体代码请参考：Github地址：创建cookieGithub地址：读取cookie 1.public void setMaxAge(int expiry)这个方法是设置Cookie的最大保存时间，即cookie的有效期。2.当服务器给浏览器回送一个cookie时，如果在服务器端没有调用setMaxAge方法设置cookie的有效期，那么cookie的有效期只在一次会话过程中有效，当用户关闭浏览器，会话就结束了，此时cookie就会失效。3.如果在服务器端使用setMaxAge方法设置了cookie的有效期，比如设置了30分钟，那么当服务器把cookie发送给浏览器时，此时cookie就会在客户端的硬盘上存储30分钟，在30分钟内，即使浏览器关了，cookie依然存在，在30分钟内，打开浏览器访问服务器时，浏览器都会把cookie一起带上，这样就可以在服务器端获取到客户端浏览器传递过来的cookie里面的信息了。 案例：存储上一次访问时间Cookie[] cookies=request.getCookies(); boolean b=false;//假设没有此cookie if(cookies!=null){ for(Cookie cookie:cookies){ String name=cookie.getName(); if("lasttime".equals(name)){ out.println("您上次登录的时间:"+cookie.getValue()); //更新 SimpleDateFormat simpleDateFormat=new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); String nowTime = simpleDateFormat.format(new java.util.Date()); //Cookie mycookie=new Cookie("lasttime",nowTime); cookie.setValue(nowTime); cookie.setMaxAge(3600); response.addCookie(cookie); b=true; break; } } } if(b==false){ out.println("first"); SimpleDateFormat simpleDateFormat=new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); String nowTime = simpleDateFormat.format(new java.util.Date()); Cookie cookie=new Cookie("lasttime",nowTime); cookie.setMaxAge(3600); response.addCookie(cookie); } 具体代码请参考：Github地址：存取上一次访问时间 案例：cookie登陆String value = request.getParameter("iskeepinfo"); String id = request.getParameter("id"); if(value!=null&amp;&amp;value.equals("keep")){ //保存id //创建cookie保存到登录用户的机器上 Cookie cookie=new Cookie("id",id); cookie.setMaxAge(3600); response.addCookie(cookie); request.getRequestDispatcher("/Ok").forward(request, response); }else if(value!=null&amp;&amp;value.equals("nokeep")){ Cookie[] cookies=request.getCookies(); for(Cookie cookie:cookies){ if(cookie.getName().equals("id")){ cookie.setMaxAge(0); response.addCookie(cookie); } } }else{ request.getRequestDispatcher("/Ok").forward(request, response); } 删除cookiecookie.setMaxAge(0)即可具体代码请参考：Github地址：登陆页面Github地址：cookie处理]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HttpServletResponse和HttpServletRequest常见应用]]></title>
      <url>%2F2016%2F03%2F14%2FHttpServletResponse%E5%92%8CHttpServletRequest%E5%B8%B8%E8%A7%81%E5%BA%94%E7%94%A8%2F</url>
      <content type="text"><![CDATA[HttpServletResponse 向客户端输出数据 //文本文件（字符） PrintWriter out = response.getWriter(); out.println("hello world"); //二进制文件（字节/字符） OutputStream os=response.getOutputStream(); os.write("hello world".getBytes()); 两个流不能同时使用，当回送字符时，PrintWriter效率更高一些，回送字节用OutputStream。 请求重定向 response.sendRedirect("/UserManager/LoginServlet");//"资源" //向下一个资源传递参数 response.sendRedirect("/UserManager/MainFrame?uname="+username+"&amp;pwd="+password); 注意当用sendRedirect传递参数时，只能传String，不能传object。此重定向会回到浏览器。 发送http响应头 response.setHeader("报头名","内容")//来设置回送 response.setContentType("text/html;charset=utf-8")//设置回送内容样式 response.setStatus()//设置状态码 response.setCharacterEncoding("utf-8") 具体内容见上一篇文章 HTTP协议详解Github地址：设置响应报头 文件下载具体内容见上一篇文章 HTTP协议详解Github地址：文件下载 HttpServletRequest 获取客户机请求头信息 //获取URL String URL=request.getRequestURL().toString(); //获取URI，web名+资源名 String URI=request.getRequestURI(); //获取请求数据 URL？username=aa&amp;pwd=123 String queryString=request.getQueryString(); //获取请求客户端IP地址 String remoteAddr=request.getRemoteAddr(); //获取web服务器IP地址 String localAddr=request.getLocalAddr(); //获取请求主机名（DNS注册），若无注册为IP地址 String remoteHost=request.getRemoteHost(); //获取web服务器主机名 String localName=request.getLocalName(); //获取客户机端口号 int remotePort=request.getRemotePort(); //获取web服务器端口号 int localPort=request.getLocalPort(); 具体代码请参考：Github地址：获取客户机信息request.getHeader(&quot;请求头名&quot;)request.getHeaderNames()可以获取所有Header头的名字具体代码请参考：Github地址：获取客户机信息 获取客户机请求参数（表单） //接收参数 String u=request.getParameter("username"); //接收复选框 String[] hobbies=request.getParameterValues("hobby"); 具体代码请参考：Github地址：获取请求参数 请求转向//将参数传递给下一个页面 request.setAttribute("u", username); request.getRequestDispatcher("/Servlet2").forward(request, response); //第二页面获取参数 String username=(String) request.getAttribute("u"); 请求转向和请求重定向的区别1.请求重定向传递参数为response.sendRedirect(&quot;/UserManager/MainFrame?uname=&quot;+username+&quot;&amp;pwd=&quot;+password);，只能传递String，请求转向传递参数为request.setAttribute(&quot;u&quot;, username)，key为String，value为object。2.请求重定向可以转向该web应用之外的URL，而请求转向不能访问此web应用，因为其发生在服务器端，没有回到浏览器端。3.请求转向地址栏显示第一次forward的URL，但数据为第二次的。4.request.setAttribute(&quot;u&quot;, username)把数据放在request域对象中，属性在一次请求中有效（请求未回到浏览器成为一次请求）。 具体代码请参考：Github地址：登陆表单Github地址：servlet1请求转向Github地址：servlet2接收]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HTTP协议详解]]></title>
      <url>%2F2016%2F03%2F14%2FHTTP%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3%2F</url>
      <content type="text"><![CDATA[http协议定义协议是指计算机通信网络中两台计算机之间进行通信所必须共同遵守的规定或规则，超文本传输协议(HTTP)是一种通信协议，它允许将超文本标记语言(HTML)文档从Web服务器传送到客户端的浏览器，目前我们使用的是HTTP/1.1 版本。 URLURL(Uniform Resource Locator) 地址用于描述一个网络上的资源，基本格式如下：schema://host[:port#]/path/.../[;url-params][?query-string][#anchor] scheme 指定低层使用的协议(例如：http, https, ftp) host 指HTTP服务器的IP地址或者域名 port# HTTP服务器的默认端口是80，这种情况下端口号可以省略。如果使用了别的端口，必须指明，例如 http://www.cnblogs.com:8080/ path 访问资源的路径 url-params，query-string 发送给http服务器的数据 anchor 锚 http是无状态的http协议是无状态的，同一个客户端的这次请求和上次请求是没有对应关系，对http服务器来说，它并不知道这两个请求来自同一个客户端。为了解决这个问题，Web程序引入了Cookie机制来维护状态。 Get和Post的区别 GET提交的数据会放在URL之后，以?分割URL和传输数据，参数之间以&amp;相连，如EditPosts.aspx?name=test1&amp;id=123456. POST方法是把提交的数据放在HTTP包的Body中 GET提交的数据大小有限制（因为浏览器对URL的长度有限制），而POST方法提交的数据没有限制 GET方式提交数据，会带来安全问题，比如一个登录页面，通过GET方式提交数据时，用户名和密码将出现在URL上，如果页面可以被缓存或者其他人可以访问这台机器，就可以从历史记录获得该用户的账号和密码 http请求http请求由三部分组成，分别是：请求行、消息报头header、请求正文body1.请求行请求方法+统一资源标识符+http协议版本当用get方法时，boby中无内容。2.消息报头request.getHeader(&quot;报头名&quot;)就可以获取报头信息。AcceptAccept请求报头域用于指定客户端接受哪些类型的信息。eg：Accept：image/gif，表明客户端希望接受GIF图象格式的资源；Accept：text/html，表明客户端希望接受html文本。Accept-CharsetAccept-Charset请求报头域用于指定客户端接受的字符集。eg：Accept-Charset:iso-8859-1,gb2312.如果在请求消息中没有设置这个域，缺省是任何字符集都可以接受。Accept-EncodingAccept-Encoding请求报头域类似于Accept，但是它是用于指定可接受的内容编码。eg：Accept-Encoding:gzip.deflate.如果请求消息中没有设置这个域服务器假定客户端对各种内容编码都可以接受。Accept-LanguageAccept-Language请求报头域类似于Accept，但是它是用于指定一种自然语言。eg：Accept-Language:zh-cn.如果请求消息中没有设置这个报头域，服务器假定客户端对各种语言都可以接受。HostHost请求报头域主要用于指定被请求资源的Internet主机和端口号，它通常从HTTP URL中提取出来的，eg：我们在浏览器中输入：http://www.bupt.edu.cn/index.html浏览器发送的请求消息中，就会包含Host请求报头域，如下：Host：www.bupt.edu.cn此处使用缺省端口号80，若指定了端口号，则变成：Host：www.bupt.edu.cn:指定端口号User-Agent服务器应用程序就是从User-Agent这个请求报头域中获取操作系统和浏览器的名称和版本。User-Agent请求报头域允许客户端将它的操作系统、浏览器和其它属性告诉服务器。不过，这个报头域不是必需的，如果我们自己编写一个浏览器，不使用User-Agent请求报头域，那么服务器端就无法得知我们的信息了。Date普通报头域表示消息产生的日期和时间。Connection普通报头域允许发送指定连接的选项。例如指定连接是连续“keep-alive”，或者指定“close”选项，通知服务器，在响应完成后，关闭连接。Referer提供了Request的上下文信息的服务器，告诉服务器我是从哪个链接过来的。用于防盗链的例子：Github地址：防盗链 String referer=request.getHeader("Referer"); if(referer==null||!referer.startsWith("http://localhost:8080/servletProject")){ response.sendRedirect("/servletProject/Error"); return; } Cookie将cookie的值发送给服务器 http响应HTTP响应也是由三个部分组成，分别是：状态行、消息报头、响应正文1.状态行服务器HTTP协议的版本+服务器发回的响应状态代码+状态代码的文本描述常用的状态码与文本描述：response.setStatus(302);response.setHeader(&quot;Location&quot;, &quot;/servletPro/Servlet2&quot;);与response.sendRedirect(&quot;/servletPro/Servlet2&quot;);相同 200 OK //客户端请求成功302 //请求资源，服务器让浏览器转向某外资源400 Bad Request //客户端请求有语法错误，不能被服务器所理解403 Forbidden //服务器收到请求，但是拒绝提供服务404 Not Found //请求资源不存在，eg：输入了错误的URL500 Internal Server Error //服务器发生不可预期的错误503 Server Unavailable //服务器当前不能处理客户端的请求，一段时间后可能恢复正常 2.消息报头response.setHeader(&quot;报头名&quot;,&quot;内容&quot;)来设置回送response.setContentType(&quot;text/html;charset=utf-8&quot;)设置回送内容样式response.setStatus()设置状态码response.setCharacterEncoding(&quot;utf-8&quot;)具体代码请参考：Github地址：设置响应报头Location用于重定向接受者到一个新的位置。Location响应报头域常用在更换域名的时候。Server包含了服务器用来处理请求的软件信息。Content-Encoding、Content-Length、Content-Language关于回送的字节信息Content-TypeContent-Type实体报头域用语指明发送给接收者的实体正文的媒体类型。eg：Content-Type:text/html;charset=ISO-8859-1Content-Type:text/html;charset=GB2312Last-ModifiedLast-Modified实体报头域用于指示资源的最后修改日期和时间。Refresh设置过多久刷新到此URL。定时刷新：response.setHeader(&quot;Refresh&quot;, &quot;5;url=/servletProject2/ResponseTest&quot;);Content-Disposition告诉浏览器有文件要下载。response.setHeader(&quot;Content-Disposition&quot;, &quot;attachment;filename=&quot;+文件);文件下载例子：Github地址：文件下载 先把资源读到servlet当中，再写给浏览器set-cookie为浏览器设置cookie。Expires、Cache-control、Pragrma告诉浏览器如何缓存 //不缓存 response.setDateHeader("Expires", -1); response.setHeader("Cache-Control","no-cache"); response.setHeader("Pragma","no-cache"); //缓存一个小时 response.setDateHeader("Expires", System.currentTimeMillis()+3600*1000*24);]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[servlet生命周期及web.xml配置]]></title>
      <url>%2F2016%2F03%2F13%2Fservlet%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E5%8F%8Aweb.xml%E9%85%8D%E7%BD%AE%2F</url>
      <content type="text"><![CDATA[Servlet工作原理 浏览器向web服务器发送http请求 web服务器解析主机地址，解析webapps，解析资源名，向web.xml查询servlet位置 web服务器创建HttpServletRequest对象，将http请求封装在里面 web服务器创建HttpServletResponse对象 创建servlet实例，第一调用时执行init()，只执行一次，之后调用doGet()和doPost()方法 HttpServlet调用doGet()和doPost()的HttpServletRequest的有关方法获取http请求 HttpServlet调用doGet()和doPost()的HttpServletResponse的有关方法生成响应数据 web服务器将HttpServletResponse对象分解为http请求 浏览器接收http请求 destroy()方法也只调用一次，当reload，关闭tomcat或者关机等时 web.xml配置12345678910111213141516171819&lt;servlet&gt; &lt;servlet-name&gt;Servlet名字&lt;/servlet-name&gt; &lt;servlet-class&gt;此servlet全路径&lt;/servlet-class&gt; &lt;!-- 定义参数 --&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;vision&lt;/param-name&gt; &lt;param-value&gt;1.0&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;Servlet名字&lt;/servlet-name&gt; &lt;url-pattern&gt;/Servlet名字&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 1.自动初始化当配置中无&lt;load-on-startup&gt;&lt;/load-on-startup&gt;时，只有第一次访问此servlet时才会实例化并调用init()方法，当配置了&lt;load-on-startup&gt;&lt;/load-on-startup&gt;后，只要开启web服务器就会调用init()方法，设置的整数值越大，表示优先级越大。相关代码请参考：Github地址: init初始化代码Github地址: 发邮件代码 2.读取初始化参数读取特定名字的参数：this.getServletConfig().getInitParameter(&quot;名字&quot;)获取所有参数名字：this.getServletConfig().getInitParameterNames()相关代码请参考：Github地址: 读取初始化参数]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[git总结]]></title>
      <url>%2F2016%2F02%2F06%2Fgit%E6%80%BB%E7%BB%93%2F</url>
      <content type="text"><![CDATA[Linux下安装gitsudo apt-get install git或者sudo apt-get install git-core Mac OS X下安装git首次需要安装homebrew，它的命令是：/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;然后用homebrew安装git，命令是：brew install git,安装后输入git --version查看git安装是否成功，我的电脑显示git version 2.7.0 Windows下安装gitLinux或Mac大法好，赶紧换系统吧亲。 安装完后需要设置:12$ git config --global user.name "Your Name"$ git config --global user.email "email@example.com" git命令 以下只做命令总结，方便自己用到时能快速查询，学习git请点传送门：Git教程传送门建立仓库：git init把文件从工作区加到暂存区：git add [filename]文件提交到仓库：git commit -m &quot;balabala&quot;查看当前仓库状态：git status仓库状态为文件修改过，查看上一次修改情况：git diff [filename]查看提交历史：git log简化日志内容：git log --pretty=oneline回到上一版本：git reset --hard HEAD^回到上上一版本：git reset --hard HEAD^^回到前100版本：git reset --hard HEAD~100去到未来版本，commit_id为未来版本号：git reset --hard [commit_id]查看命令历史，包含commit_id等信息：git reflog查看工作区和版本库最新版本的区别：git diff HEAD -- [filename]丢弃工作区的修改回到和版本库一样；撤回修改到添加暂存区后状态：git checkout -- [filename]暂存区的修改撤销掉，重新放回工作区。再用上一条丢弃工作区修改：git reset HEAD [filename]从版本库中删除该文件并git commit：git rm [filename]本地关联github远程库：git remote add origin git@github.com:bupthuangxin/仓库名.git本地库所有内容推送到远程库：git push -u origin master远程库克隆本地库：git clone git@github.com:bupthuangxin/仓库名.git创建dev分支并切换至dev：git checkout -b dev创建dev分支：git branch dev切换至dev分支：git checkout dev查看当前分支：git branch在master分支时，合并两分支，Fast-forward方式：git merge dev删除dev分支：git branch -d dev查看分支合并图：git log --graph --pretty=oneline --abbrev-commit禁用Fast-forward方式进行合并：git merge --no-ff -m &quot;balabala&quot; dev储藏当前分支的工作现场：git stash查看当前分支工作现场：git stash list恢复工作：git stash apply删除stash内容：git stash drop恢复并删除stash内容：git stash pop强行删除分支（分支还没合并）：git branch -D dev查看远程库信息：git remote -v此分支推送远程库：git push origin [分支名]克隆远程库只能看见master分支，切换到dev分支：git checkout -b dev origin/dev推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并：git pull如果git pull提示“no tracking information”，则说明本地分支和远程分支的链接关系没有创建：git branch --set-upstream branch-name origin/branch-name给当前版本打标签：git tag [标签名]查看所有标签：git tag给之前的版本打标签：git tag [标签名] [commit_id]查看标签信息：git show [标签名]用-a指定标签名，-m指定说明文字：git tag -a [标签名] -m &quot;balabala&quot; [commit_id]删除标签：git tag -d [标签名]推送标签到远程：git push origin [标签名]推送全部尚未推送到远程的本地标签：git push origin --tags删除远程标签：git push origin :refs/tags/[标签名]]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[request和response中文乱码]]></title>
      <url>%2F2016%2F02%2F03%2Frequest%E5%92%8Cresponse%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%2F</url>
      <content type="text"><![CDATA[request和response中文乱码及解决方法request乱码指的是：浏览器向服务器发送的请求参数中包含中文字符，服务器获取到的请求参数的值是乱码；response乱码指的是：服务器向浏览器发送的数据包含中文字符，浏览器中显示的是乱码; 乱码产生的原因：不管是request乱码还是response乱码，其实都是由于浏览器跟服务器端采用的编码格式不一致造成的。以request乱码为例：浏览器向服务器发送请求，因为浏览器与服务器之间的通信实质上是socket流，所以要先将请求参数（字符）转换成字节(编码过程)，服务器接收到请求参数后进行解码（字节转字符），然后封装到request对象中。如果客户端的编码与服务器端的解码不统一，就会导致通过request获取到的请求参数的值是乱码。 response乱码服务器发给浏览器的数据默认是按照ISO-8859-1编码，浏览器接收到数据后按照默认的字符集进行解码后显示，如果浏览器的默认解码字符集不是ISO-8859-1，就出现乱码。对于response乱码，只需要在服务器端指定一个编码字符集，然后通知浏览器按照这个字符集进行解码就可以了。1.A设置服务器端的编码response.setCharacterEncoding(&quot;utf-8&quot;);该方法必须在response.getWriter()之前进行设置。B通知浏览器服务器发送的数据格式response.setContentType(&quot;text/html;charset=utf-8&quot;);等价于response.setHeader(&quot;contentType&quot;, &quot;text/html; charset=utf-8&quot;);C浏览器使用utf-8进行解码2.当用到response.sendRedirect(&quot;____?name=&quot;+u)转向时，u一定要为iso-8859-1编码方式，否则容易出现乱码。将utf-8编码的中文转为iso-8859-1编码：String u=new String(uu.getBytes(&quot;utf-8&quot;),&quot;iso-8859-1&quot;);//uu为utf-8编码的中文中文u的值传入到转向的servlet，iso-8859-1自动转为utf-8编码，若无自动转换，用上述转换代码进行转换。 request乱码从浏览器发起的访问方式有三种：在地址栏直接输入URL访问、点击页面中的超链接访问、提交表单访问。第一种访问方式浏览器默认将参数按照utf-8进行编码，后面两种访问方式浏览器将参数按照当前页面的显示编码进行编码。所以对于request乱码，只需要在服务器端设置相应的解码格式即可。由于访问方式不同，浏览器对参数的编码格式也不同，为了方便处理，通过超链接和表单的访问也规定必须是utf-8格式，即显示当前页面的编码也要使用utf-8，这样浏览器将统一使用utf-8对参数进行编码。1.post方式属于表单提交，参数存在于请求体中。request.setCharacterEncoding(&quot;utf-8&quot;)2.get方式属于表单提交，参数存在URL中，服务器按照默认的iso-8859-1进行解码String u=new String(request.getParameter(&quot;&quot;).getBytes(&quot;iso-8859-1&quot;),&quot;utf-8&quot;)3.超链接访问中有中文参数时，可以修改服务器端对URL参数的默认编码。在tomcat的server.xml中，设置元素的属性URIEncoding=”UTF-8”即可。以上只要涉及URL中有中文都可试着用此方法解决。 利用过滤器解决乱码问题：在Filter的init方法中获取web.xml的filter编码设置：String charEncoding=fConfig.getInitParameter(&quot;encoding&quot;);在Filter的doFilter方法中设置： //当前应用的默认编码与请求的编码值不相同，执行 if(!charEncoding.equal(request.getCharacterEncoding())){ request.getCharacterEncoding(charEncoding)； } response.getCharacterEncoding(charEncoding)； web.xml配置&lt;filter&gt;&lt;init-param&gt;&lt;param-name&gt;encoding&lt;/param-name&gt;&lt;param-value&gt;UTF-8&lt;/param-value&gt;&lt;/init-param&gt;&lt;/filter&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>%2F2016%2F01%2F28%2Fhello-world%2F</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
    </entry>

    
  
  
</search>
